// Copyright © 2024 The µcad authors <info@ucad.xyz>
// SPDX-License-Identifier: AGPL-3.0-or-later

//! Generate tests out of *Markdown* files which include µcad code
//!
//! Path will be scanned recursively for *Markdown* files (`*.md`).
//! Code must be marked by *Markdown* code markers (code type: `µcad`) with a test ID attached.
//! In case of a failing test `#fail` must be appended to the test ID.
//!
//! Relative path's of scanned folder names will be used to build a modules structure
//! in the resulting code.
//! If test IDs include `.` name will be split into several names which will be
//! used to crates sub modules.

mod output;

use anyhow::{Context, Result};
use output::Output;
use std::{io::Write, path::Path};

/// for debugging purpose
#[allow(unused)]
macro_rules! warning {
    ($($tokens: tt)*) => {
        // HINT: switch `note` -> `warning` to activate debug messages
        println!("cargo:note={}", format!($($tokens)*))
    }
}

#[test]
fn md_tests() {
    env_logger::init();

    println!("Generating Markdown Tests...");
    std::env::set_var("OUT_DIR", "../../target");
    generate("..").unwrap();
}

/// Generate tests from the *Markdown* files which are within the given `path`
///
/// Path will be scanned recursively
pub fn generate(path: impl AsRef<Path>) -> Result<()> {
    use std::*;

    // get target path
    let out_dir = env::var("OUT_DIR")?;
    let dest_path = path::Path::new(&out_dir).join("microcad_markdown_test.rs");
    // we will create a single output file whose content will be written into this variable first
    let mut code = String::from(
        r#"// This code was generated by microcad_markdown_test
// Copyright © 2024 The µcad authors <info@ucad.xyz>
// SPDX-License-Identifier: AGPL-3.0-or-later

use std as rust_std;

"#,
    );

    // directories to exclude
    let exclude_dirs = ["target", "thirdparty"];

    let mut test_outputs = Vec::new();

    // read all *Markdown files and write result into `code`
    scan(
        &mut code,
        path.as_ref(),
        "md",
        &exclude_dirs,
        &mut test_outputs,
    )?;

    std::fs::File::create("../doc/test_list.md")
        .expect("file access error")
        .write_all(make_test_list(&test_outputs).as_bytes())
        .expect("write error");

    // remove any previous banners
    remove_banners(path, &exclude_dirs, &test_outputs)?;

    // reformat code and write into file
    match rustfmt_wrapper::rustfmt(code) {
        Ok(code) =>
        // write all rust code at once
        {
            fs::write(&dest_path, code).context(format!("cannot create file '{dest_path:?}'"))?;
            Ok(())
        }
        Err(rustfmt_wrapper::Error::Rustfmt(msg)) => {
            Err(anyhow::Error::msg(msg.clone())).context(msg)
        }
        Err(err) => Err(anyhow::Error::new(err)),
    }
}

fn make_test_list(tests: &[Output]) -> String {
    let count = tests.len();
    let mut result = format!(
        "# Test List

The following table lists all tests included in this documentation.
Click on the test names to jump to file with the test or click the buttons to get the logs.

**{count}** tests from markdown.

| Result | Name |
|-------:|------|
"
    );

    {
        let mut tests = tests.iter().collect::<Vec<_>>().clone();
        tests.sort();
        tests.iter().for_each(|test| {
            result.push_str(&test.to_string());
        });
    }

    result
}

/// Remove all banners in `path` and exclude folders whose names are contained
/// in `exclude_dirs` from search.
fn remove_banners(
    path: impl AsRef<Path>,
    exclude_dirs: &[&str],
    exclude_outputs: &[Output],
) -> Result<()> {
    //warning!("remove_banners: {:?} {exclude_files:?}", path.as_ref());
    for entry in std::fs::read_dir(&path)?.flatten() {
        // get file type
        if let Ok(file_type) = entry.file_type() {
            // check if directory or file
            if file_type.is_dir()
                && !exclude_dirs.contains(&entry.file_name().to_string_lossy().to_string().as_str())
            {
                if entry.file_name() == ".test" {
                    clean_dir(entry.path(), exclude_outputs)?;
                } else {
                    remove_banners(entry.path(), exclude_dirs, exclude_outputs)?;
                }
            }
        }
    }

    Ok(())
}

/// Remove all files within `.test` directory
fn clean_dir(path: impl AsRef<Path>, exclude_files: &[Output]) -> Result<()> {
    warning!("remove banners in: {:?}", path.as_ref());

    // list all files within `.test` directory and remove them
    for entry in std::fs::read_dir(&path)
        .unwrap()
        .flatten()
        .filter(|entry| entry.file_type().unwrap().is_file())
    {
        if 0 == exclude_files
            .iter()
            .filter(|f| f.has_path(&entry.path()))
            .count()
        {
            // warning!("remove: {:?}", entry.path());
            std::fs::remove_file(entry.path())?;
        }
    }
    Ok(())
}

/// scan folder
fn scan(
    output: &mut String,
    path: &Path,
    extension: &str,
    exclude_dirs: &[&str],
    test_outputs: &mut Vec<Output>,
) -> Result<bool> {
    // prepare return value
    let mut found = false;
    // read given directory
    for entry in std::fs::read_dir(path)?.flatten() {
        // get file type
        if let Ok(file_type) = entry.file_type() {
            let file_name = entry.file_name().into_string().unwrap();
            // check if directory or file
            if file_type.is_dir() && !exclude_dirs.contains(&file_name.as_str()) {
                let mut code = String::new();
                // scan deeper
                if scan(
                    &mut code,
                    &entry.path(),
                    extension,
                    exclude_dirs,
                    test_outputs,
                )? {
                    if let Some(name) = entry.path().file_stem() {
                        let name = name.to_str().unwrap();
                        output.push_str(&format!(
                            "#[allow(non_snake_case)]
                             mod r#{name} {{
                                 {code}
                             }}\n\n"
                        ))
                    } else {
                        output.push_str(&code);
                    }

                    // found something
                    found = true;
                }
            } else if file_type.is_file()
                && file_name.ends_with(&format!(".{extension}"))
                && !scan_for_tests(output, &entry.path(), test_outputs)?
            {
                // tell cargo to watch this file
                println!("cargo:rerun-if-changed={}", entry.path().display());
                // found something
                found = true;
            }
        }
    }

    Ok(found)
}

/// Read single *Markdown* file and collect included tests in `tree`.
///
/// Generates tree nodes if name can be split into several names which are separated by `.`.
fn scan_for_tests(
    output: &mut String,
    file_path: &Path,
    test_outputs: &mut Vec<Output>,
) -> Result<bool> {
    use regex::*;
    use std::{fs::*, io::*};

    // `true`` if we didn't found anything
    let mut result = true;

    // load markdown file
    let mut md_content = String::new();
    {
        File::open(file_path)?.read_to_string(&mut md_content)?;
    }

    // accumulate name and code while reading file
    let mut test_name = String::new();
    let mut test_code = String::new();

    let start = Regex::new(r#"```[mµ][Cc][Aa][Dd](,(?<name>[\.#_\w]+))?"#).expect("bad regex");
    let end = Regex::new(r#"```"#).expect("bad regex");

    let mut ignore = false;
    // read all lines in the file
    for line in md_content.lines() {
        // ignore deeper markdown code
        if line.starts_with("````") {
            ignore = !ignore;
            warning!("ignoring: {ignore}");
        }

        if !ignore {
            // match code starting marker
            if let Some(start) = start.captures_iter(line).next() {
                if let Some(name) = start.name("name") {
                    // remember test name
                    test_name = name.as_str().to_string();
                    // clear code
                    test_code.clear();
                }
            } else if !test_name.is_empty() {
                // match code end marker
                if end.captures_iter(line).next().is_some() {
                    if let Some(output) =
                        create_test(output, file_path, test_name.as_str(), test_code.as_str())
                    {
                        test_outputs.push(output);
                    }

                    // clear name to signal new test awaited
                    test_name.clear();

                    // found some test
                    result = false;
                } else {
                    // add line to code
                    test_code.push_str(line);
                    test_code.push('\n');
                }
            }
        }
    }
    Ok(result)
}

/// Generate code for one test
fn create_test<'a>(
    f: &mut String,
    file_path: &'a Path,
    name: &'a str,
    code: &str,
) -> Option<Output> {
    // split name into `name` and optional `mode`
    let (name, mode) = if let Some((name, mode)) = name.split_once('#') {
        (name, Some(mode))
    } else {
        (name, None)
    };

    warning!(
        "create test: {name}\t{}\t{file_path:?}",
        if let Some(mode) = mode {
            format!("{mode} ")
        } else {
            "".to_string()
        }
    );

    // where to store generated output
    let test_path = file_path.parent().unwrap().join(".test");
    // banner image file of this test
    let banner = test_path.join(format!("{name}.png"));
    // log file of this test
    let log = test_path.join(format!("{name}.log"));

    // maybe create .test directory
    let _ = std::fs::create_dir(test_path);

    // Early exit for "#no_test" and "#todo" suffixes
    if mode == Some("no_test") {
        return None;
    }

    f.push_str(&create_test_code(name, mode, code, &banner, &log));

    Some(Output::new(name.into(), file_path.into(), banner, log))
}

/// create test code
/// - `name`: name of the test
/// - `mode`: test result expectation
/// - `code`: µcad code to test
/// - `banner`: file for banner link
/// - `log`: file for log output
/// - `todo`:
fn create_test_code(
    name: &str,
    mode: Option<&str>,
    code: &str,
    banner: &std::path::Path,
    out: &std::path::Path,
) -> String {
    let banner = banner.to_string_lossy().escape_default().to_string();
    let out = out.to_string_lossy().escape_default().to_string();
    let todo = mode == Some("todo");

    format!(
        r##"#[test]
                #[allow(non_snake_case)]
                fn r#{name}() {{
                    use crate::rust_std::fs;
                    use crate::rust_std::io;
                    use crate::rust_std::io::Write;

                    use microcad_builtin::*;
                    use microcad_lang::diag::*;
                    use microcad_lang::eval::*;
                    use microcad_lang::syntax::*;

                    microcad_lang::env_logger_init();

                    // get parameters from outside code
                    let banner = "{banner}";
                    let out_name = "{out}";
                    #[allow(unused)]
                    let todo = {todo};

                    // remove generated files before updating
                    let _ = fs::remove_file(banner);
                    let _ = fs::remove_file(out_name);

                    // create log file
                    let out = &mut fs::File::create(out_name).expect("cannot create log file");
                    let out = &mut io::BufWriter::new(out);

                    // load and handle µcad source file
                    match SourceFile::load_from_str(
                        r#"
                        {code}"#,
                    ) {handling};
                }}"##,
        // generate handling code dependant of what result we are awaiting
        handling = match mode {
            // test is expected to fail?
            Some("fail") =>
                r##"{
                        // test expected to fail failed at parsing?
                        Err(err) => {
                            out.write_all(format!("{err}").as_bytes()).unwrap();
                            let _ = fs::hard_link("images/fail_ok.png", banner);
                            log::debug!("{err}")
                        },
                        // test expected to fail succeeded at parsing?
                        Ok(source) => {
                            // evaluate the code including µcad std library
                            let mut context = EvalContext::from_source_captured(source.clone(), builtin_namespace(), &["../lib".into()]);
                            let eval = context.eval();

                            // get print output
                            write!(out, "{}", context.output().expect("capture error")).expect("output error");

                            // print any error
                            context.write_diagnosis(out).expect("internal error");

                            // check if test expected to fail failed at evaluation
                            match (eval, context.has_errors()) {
                                // evaluation had been aborted?
                                (Err(err),_) => {
                                    let _ = fs::hard_link("images/fail_ok.png", banner);
                                    log::debug!("{err}");
                                }
                                // evaluation produced errors?
                                (_,true) => {
                                    let _ = fs::hard_link("images/fail_ok.png", banner);
                                   log::debug!("there were {error_count} errors (see {out_name})", error_count = context.error_count());
                                 }
                                // test expected to fail but succeeds?
                                (_,_) => {
                                    let _ = fs::hard_link("images/ok_fail.png", banner);
                                    panic!("ERROR: test is marked to fail but succeeded");
                                }
                            }
                        }
                    }"##,
            // test is expected to succeed?
            _ =>
                r##"{
                        // test awaited to succeed and parsing failed?
                        Err(err) => {
                            out.write_all(format!("{err}").as_bytes()).unwrap();
                            if todo {
                                let _ = fs::hard_link("images/todo.png", banner);
                            } else {
                                let _ = fs::hard_link("images/fail.png", banner);
                                panic!("ERROR: {err}")
                            }
                        },
                        // test awaited to succeed and parsing succeeds?
                        Ok(source) => {
                            // evaluate the code including µcad std library
                            let mut context = EvalContext::from_source_captured(source.clone(), builtin_namespace(), &["../lib".into()]);
                            let eval = context.eval();
                            
                            // get print output
                            write!(out, "{}", context.output().expect("capture error")).expect("output error");

                            // print any error
                            context.write_diagnosis(out).expect("internal error");

                            // check if test awaited to succeed but failed at evaluation
                            match (eval, context.has_errors(), todo) {
                                // test expected to succeed and succeeds with no errors
                                (Ok(_),false,false) => { let _ = fs::hard_link("images/ok.png", banner); }
                                // test is todo but succeeds with no errors
                                (Ok(_),false,true) => { let _ = fs::hard_link("images/not_todo.png", banner); }
                                // Any error but todo
                                (_,_,true) => {
                                    let _ = fs::hard_link("images/todo.png", banner);
                                }
                                // evaluation had been aborted?
                                (Err(err),_,_) => {
                                    let _ = fs::hard_link("images/fail.png", banner);
                                    out.write_all(format!("{err}").as_bytes()).unwrap();
                                    panic!("ERROR: {err}")
                                }
                                // evaluation produced errors?
                                (_,true,_) => {
                                    let _ = fs::hard_link("images/fail.png", banner);
                                    panic!("ERROR: there were {error_count} errors (see {out_name})", error_count = context.error_count());
                                }
                            }
                        },
                    }"##,
        }
    )
}
